[2025-09-25 10:35:17,289] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: manga_prediction_pipeline.data_ingestion manual__2025-09-25T10:35:13+00:00 [queued]>
[2025-09-25 10:35:17,291] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: manga_prediction_pipeline.data_ingestion manual__2025-09-25T10:35:13+00:00 [queued]>
[2025-09-25 10:35:17,291] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2025-09-25 10:35:17,291] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2025-09-25 10:35:17,292] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2025-09-25 10:35:17,296] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): data_ingestion> on 2025-09-25 10:35:13+00:00
[2025-09-25 10:35:17,298] {standard_task_runner.py:52} INFO - Started process 575 to run task
[2025-09-25 10:35:17,299] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'manga_prediction_pipeline', 'data_ingestion', 'manual__2025-09-25T10:35:13+00:00', '--job-id', '265', '--raw', '--subdir', 'DAGS_FOLDER/manga_prediction_pipeline.py', '--cfg-path', '/tmp/tmpce5xiwg2', '--error-file', '/tmp/tmpogc0v1tz']
[2025-09-25 10:35:17,300] {standard_task_runner.py:80} INFO - Job 265: Subtask data_ingestion
[2025-09-25 10:35:17,316] {task_command.py:370} INFO - Running <TaskInstance: manga_prediction_pipeline.data_ingestion manual__2025-09-25T10:35:13+00:00 [running]> on host 19d9b7ffabd0
[2025-09-25 10:35:17,339] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=manga_prediction_pipeline
AIRFLOW_CTX_TASK_ID=data_ingestion
AIRFLOW_CTX_EXECUTION_DATE=2025-09-25T10:35:13+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-09-25T10:35:13+00:00
[2025-09-25 10:35:17,339] {logging_mixin.py:115} INFO - Reading data from /opt/***/data/manga.csv
[2025-09-25 10:35:17,651] {logging_mixin.py:115} INFO - Data read successfully. Shape: (66371, 26)
[2025-09-25 10:35:17,651] {logging_mixin.py:115} INFO - Attempting to connect to MariaDB at mariadb:3306/manga_db
[2025-09-25 10:35:17,673] {authentication.py:66} INFO - package: mysql.connector.plugins
[2025-09-25 10:35:17,673] {authentication.py:67} INFO - plugin_name: mysql_native_password
[2025-09-25 10:35:17,673] {authentication.py:71} INFO - AUTHENTICATION_PLUGIN_CLASS: MySQLNativePasswordAuthPlugin
[2025-09-25 10:35:17,676] {logging_mixin.py:115} INFO - Successfully connected to MariaDB.
[2025-09-25 10:35:17,676] {logging_mixin.py:115} INFO - Inserting into dim_manga_info...
[2025-09-25 10:35:44,742] {logging_mixin.py:115} INFO - dim_manga_info populated.
[2025-09-25 10:35:44,974] {logging_mixin.py:115} INFO - Inserting into dim_genres...
[2025-09-25 10:35:45,107] {logging_mixin.py:115} INFO - dim_genres populated.
[2025-09-25 10:35:45,110] {logging_mixin.py:115} INFO - Inserting into dim_authors...
[2025-09-25 10:35:45,112] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/src/data_ingestion.py", line 115, in ingest_data
    unique_authors = df['authors'].astype(str).dropna().apply(lambda x: json.loads(x) if isinstance(x, str) and x.startswith('[') else []).explode().apply(lambda x: x['name'] if isinstance(x, dict) else x).unique()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/series.py", line 4357, in apply
    return SeriesApply(self, func, convert_dtype, args, kwargs).apply()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/apply.py", line 1043, in apply
    return self.apply_standard()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/apply.py", line 1101, in apply_standard
    convert=self.convert_dtype,
  File "pandas/_libs/lib.pyx", line 2859, in pandas._libs.lib.map_infer
  File "/opt/airflow/src/data_ingestion.py", line 115, in <lambda>
    unique_authors = df['authors'].astype(str).dropna().apply(lambda x: json.loads(x) if isinstance(x, str) and x.startswith('[') else []).explode().apply(lambda x: x['name'] if isinstance(x, dict) else x).unique()
  File "/usr/local/lib/python3.7/json/__init__.py", line 348, in loads
    return _default_decoder.decode(s)
  File "/usr/local/lib/python3.7/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/usr/local/lib/python3.7/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 2 (char 1)
[2025-09-25 10:35:45,117] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=manga_prediction_pipeline, task_id=data_ingestion, execution_date=20250925T103513, start_date=20250925T103517, end_date=20250925T103545
[2025-09-25 10:35:45,121] {standard_task_runner.py:97} ERROR - Failed to execute job 265 for task data_ingestion (Expecting value: line 1 column 2 (char 1); 575)
[2025-09-25 10:35:45,144] {local_task_job.py:156} INFO - Task exited with return code 1
[2025-09-25 10:35:45,156] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
