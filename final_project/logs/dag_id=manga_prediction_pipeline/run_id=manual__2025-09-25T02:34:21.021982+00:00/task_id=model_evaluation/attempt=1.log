[2025-09-25 02:34:30,564] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: manga_prediction_pipeline.model_evaluation manual__2025-09-25T02:34:21.021982+00:00 [queued]>
[2025-09-25 02:34:30,567] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: manga_prediction_pipeline.model_evaluation manual__2025-09-25T02:34:21.021982+00:00 [queued]>
[2025-09-25 02:34:30,568] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2025-09-25 02:34:30,568] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2025-09-25 02:34:30,568] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2025-09-25 02:34:30,572] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): model_evaluation> on 2025-09-25 02:34:21.021982+00:00
[2025-09-25 02:34:30,575] {standard_task_runner.py:52} INFO - Started process 577 to run task
[2025-09-25 02:34:30,576] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'manga_prediction_pipeline', 'model_evaluation', 'manual__2025-09-25T02:34:21.021982+00:00', '--job-id', '64', '--raw', '--subdir', 'DAGS_FOLDER/manga_prediction_pipeline.py', '--cfg-path', '/tmp/tmps9efhcie', '--error-file', '/tmp/tmp6yvr5_ns']
[2025-09-25 02:34:30,576] {standard_task_runner.py:80} INFO - Job 64: Subtask model_evaluation
[2025-09-25 02:34:30,594] {task_command.py:370} INFO - Running <TaskInstance: manga_prediction_pipeline.model_evaluation manual__2025-09-25T02:34:21.021982+00:00 [running]> on host 6afc1fdecefc
[2025-09-25 02:34:30,617] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=manga_prediction_pipeline
AIRFLOW_CTX_TASK_ID=model_evaluation
AIRFLOW_CTX_EXECUTION_DATE=2025-09-25T02:34:21.021982+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-09-25T02:34:21.021982+00:00
[2025-09-25 02:34:30,617] {logging_mixin.py:115} INFO - Reading feature-engineered data from /opt/***/data/features/manga_features.parquet for evaluation split
[2025-09-25 02:34:30,657] {logging_mixin.py:115} INFO - X_test shape: (3128, 11), y_test shape: (3128,)
[2025-09-25 02:34:30,676] {logging_mixin.py:115} WARNING - 2025/09/25 02:34:30 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2025-09-25 02:34:30,683] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/search_utils.py", line 214, in _get_identifier
    entity_type, key = identifier.split(".", 1)
ValueError: not enough values to unpack (expected 2, got 1)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/src/model_evaluation.py", line 42, in model_evaluation
    max_results=1
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/tracking/client.py", line 1800, in search_runs
    experiment_ids, filter_string, run_view_type, max_results, order_by, page_token
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/tracking/_tracking_service/client.py", line 561, in search_runs
    page_token=page_token,
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/abstract_store.py", line 307, in search_runs
    experiment_ids, filter_string, run_view_type, max_results, order_by, page_token
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/store/tracking/file_store.py", line 887, in _search_runs
    sorted_runs = SearchUtils.sort(filtered, order_by)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/search_utils.py", line 583, in sort
    (key_type, key, ascending) = cls.parse_order_by_for_search_runs(order_by_clause)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/search_utils.py", line 526, in parse_order_by_for_search_runs
    identifier = cls._get_identifier(token_value.strip(), cls.VALID_ORDER_BY_ATTRIBUTE_KEYS)
  File "/home/airflow/.local/lib/python3.7/site-packages/mlflow/utils/search_utils.py", line 220, in _get_identifier
    error_code=INVALID_PARAMETER_VALUE,
mlflow.exceptions.MlflowException: Invalid identifier 'start_time'. Columns should be specified as 'attribute.<key>', 'metric.<key>', 'tag.<key>', or 'param.'.
[2025-09-25 02:34:30,687] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=manga_prediction_pipeline, task_id=model_evaluation, execution_date=20250925T023421, start_date=20250925T023430, end_date=20250925T023430
[2025-09-25 02:34:30,693] {standard_task_runner.py:97} ERROR - Failed to execute job 64 for task model_evaluation (Invalid identifier 'start_time'. Columns should be specified as 'attribute.<key>', 'metric.<key>', 'tag.<key>', or 'param.'.; 577)
[2025-09-25 02:34:30,715] {local_task_job.py:156} INFO - Task exited with return code 1
[2025-09-25 02:34:30,730] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
